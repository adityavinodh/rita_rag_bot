# -*- coding: utf-8 -*-
"""emanual_scraper

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HIeLutUs_pWkeRkiaL-HP6aHf3LqoNXL
"""

from bs4 import BeautifulSoup

# Replace this with the actual HTML content of the <nav> section with brand names
html_content = '''<nav class="nav--brand nav" data-v-c4377d1e=""><!--[--><!--]--><!--[--><a href="/silvercrest" class="nav__item" style="--color: #000000;" data-v-c4377d1e=""><div class="smart-image nav__img" title="SilverCrest" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><source srcset="/thumbs/brands/s/1401-silvercrest_logo.webp" type="image/webp" data-v-1460e71d=""><img src="/thumbs/brands/s/1401-silvercrest_logo.jpg" width="100" height="100" alt="SilverCrest manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">SilverCrest</span></a><a href="/singer" class="nav__item" style="--color: #000000;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Singer" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><!----><img src="/thumbs/brands/s/250-singer_logo.svg" width="100" height="100" alt="Singer manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Singer</span></a><a href="/husqvarna" class="nav__item" style="--color: #000000;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Husqvarna" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><source srcset="/thumbs/brands/s/199-husqvarna_logo.webp" type="image/webp" data-v-1460e71d=""><img src="/thumbs/brands/s/199-husqvarna_logo.jpg" width="100" height="100" alt="Husqvarna manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Husqvarna</span></a><a href="/philips" class="nav__item" style="--color: #0e5fd8;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Philips" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><!----><img src="/thumbs/brands/s/12-philips_logo.svg" width="100" height="100" alt="Philips manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Philips</span></a><a href="/bosch" class="nav__item" style="--color: #e52d27;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Bosch" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><!----><img src="/thumbs/brands/s/10-bosch_logo.svg" width="100" height="100" alt="Bosch manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Bosch</span></a><a href="/yamaha" class="nav__item" style="--color: #48217a;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Yamaha" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><!----><img src="/thumbs/brands/s/151-yamaha_logo.svg" width="100" height="100" alt="Yamaha manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Yamaha</span></a><a href="/casio" class="nav__item" style="--color: #003296;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Casio" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><!----><img src="/thumbs/brands/s/165-casio_logo.svg" width="100" height="100" alt="Casio manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Casio</span></a><a href="/oregon-scientific" class="nav__item" style="--color: #000000;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Oregon Scientific" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><source srcset="/thumbs/brands/s/1772-oregon-scientific_logo.webp" type="image/webp" data-v-1460e71d=""><img src="/thumbs/brands/s/1772-oregon-scientific_logo.jpg" width="100" height="100" alt="Oregon Scientific manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Oregon Scientific</span></a><a href="/delonghi" class="nav__item" style="--color: #052644;" data-v-c4377d1e=""><div class="smart-image nav__img" title="DeLonghi" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><source srcset="/thumbs/brands/s/131-delonghi_logo.webp" type="image/webp" data-v-1460e71d=""><img src="/thumbs/brands/s/131-delonghi_logo.jpg" width="100" height="100" alt="DeLonghi manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">DeLonghi</span></a><a href="/siemens" class="nav__item" style="--color: #009999;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Siemens" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><!----><img src="/thumbs/brands/s/175-siemens_logo.svg" width="100" height="100" alt="Siemens manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Siemens</span></a><a href="/ariston-thermo" class="nav__item" style="--color: #2d3047;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Ariston Thermo" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><source srcset="/thumbs/brands/s/2823-ariston-thermo_logo.webp" type="image/webp" data-v-1460e71d=""><img src="/thumbs/brands/s/2823-ariston-thermo_logo.jpg" width="100" height="100" alt="Ariston Thermo manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Ariston Thermo</span></a><a href="/beko" class="nav__item" style="--color: #0081cf;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Beko" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><source srcset="/thumbs/brands/s/690-beko_logo.webp" type="image/webp" data-v-1460e71d=""><img src="/thumbs/brands/s/690-beko_logo.jpg" width="100" height="100" alt="Beko manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Beko</span></a><a href="/motorola" class="nav__item" style="--color: #000000;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Motorola" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><source srcset="/thumbs/brands/s/62-motorola_logo.webp" type="image/webp" data-v-1460e71d=""><img src="/thumbs/brands/s/62-motorola_logo.jpg" width="100" height="100" alt="Motorola manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Motorola</span></a><a href="/panasonic" class="nav__item" style="--color: #0048aa;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Panasonic" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><!----><img src="/thumbs/brands/s/63-panasonic_logo.svg" width="100" height="100" alt="Panasonic manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Panasonic</span></a><a href="/pfaff" class="nav__item" style="--color: #da2132;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Pfaff" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><source srcset="/thumbs/brands/s/548-pfaff_logo.webp" type="image/webp" data-v-1460e71d=""><img src="/thumbs/brands/s/548-pfaff_logo.jpg" width="100" height="100" alt="Pfaff manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Pfaff</span></a><a href="/stokke" class="nav__item" style="--color: #ed7703;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Stokke" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><!----><img src="/thumbs/brands/s/1698-stokke_logo.svg" width="100" height="100" alt="Stokke manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Stokke</span></a><a href="/onkyo" class="nav__item" style="--color: #1c63b7;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Onkyo" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><!----><img src="/thumbs/brands/s/122-onkyo_logo.svg" width="100" height="100" alt="Onkyo manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Onkyo</span></a><a href="/danfoss" class="nav__item" style="--color: #ed1c24;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Danfoss" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><!----><img src="/thumbs/brands/s/1491-danfoss_logo.svg" width="100" height="100" alt="Danfoss manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Danfoss</span></a><a href="/bernina" class="nav__item" style="--color: #e2001a;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Bernina" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><source srcset="/thumbs/brands/s/1568-bernina_logo.webp" type="image/webp" data-v-1460e71d=""><img src="/thumbs/brands/s/1568-bernina_logo.jpg" width="100" height="100" alt="Bernina manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Bernina</span></a><a href="/gorenje" class="nav__item" style="--color: #00b9ad;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Gorenje" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><source srcset="/thumbs/brands/s/1002-gorenje_logo.webp" type="image/webp" data-v-1460e71d=""><img src="/thumbs/brands/s/1002-gorenje_logo.jpg" width="100" height="100" alt="Gorenje manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Gorenje</span></a><a href="/vaillant" class="nav__item" style="--color: #000000;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Vaillant" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><source srcset="/thumbs/brands/s/1467-vaillant_logo.webp" type="image/webp" data-v-1460e71d=""><img src="/thumbs/brands/s/1467-vaillant_logo.jpg" width="100" height="100" alt="Vaillant manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Vaillant</span></a><a href="/amica" class="nav__item" style="--color: #c00c14;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Amica" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><source srcset="/thumbs/brands/s/1026-amica_logo.webp" type="image/webp" data-v-1460e71d=""><img src="/thumbs/brands/s/1026-amica_logo.jpg" width="100" height="100" alt="Amica manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Amica</span></a><a href="/sharp" class="nav__item" style="--color: #e6000d;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Sharp" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><!----><img src="/thumbs/brands/s/268-sharp_logo.svg" width="100" height="100" alt="Sharp manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Sharp</span></a><a href="/neff" class="nav__item" style="--color: #000000;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Neff" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><source srcset="/thumbs/brands/s/1025-neff_logo.webp" type="image/webp" data-v-1460e71d=""><img src="/thumbs/brands/s/1025-neff_logo.jpg" width="100" height="100" alt="Neff manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Neff</span></a><a href="/aeg" class="nav__item" style="--color: #d31937;" data-v-c4377d1e=""><div class="smart-image nav__img" title="AEG" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><!----><img src="/thumbs/brands/s/24-aeg_logo.svg" width="100" height="100" alt="AEG manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">AEG</span></a><a href="/miele" class="nav__item" style="--color: #000000;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Miele" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><source srcset="/thumbs/brands/s/124-miele_logo.webp" type="image/webp" data-v-1460e71d=""><img src="/thumbs/brands/s/124-miele_logo.jpg" width="100" height="100" alt="Miele manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Miele</span></a><a href="/cybex" class="nav__item" style="--color: #000000;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Cybex" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><source srcset="/thumbs/brands/s/1674-cybex_logo.webp" type="image/webp" data-v-1460e71d=""><img src="/thumbs/brands/s/1674-cybex_logo.jpg" width="100" height="100" alt="Cybex manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Cybex</span></a><a href="/hoover" class="nav__item" style="--color: #ec2426;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Hoover" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><!----><img src="/thumbs/brands/s/229-hoover_logo.svg" width="100" height="100" alt="Hoover manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Hoover</span></a><a href="/samsung" class="nav__item" style="--color: #1428a0;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Samsung" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><source srcset="/thumbs/brands/s/9-samsung_logo.webp" type="image/webp" data-v-1460e71d=""><img src="/thumbs/brands/s/9-samsung_logo.jpg" width="100" height="100" alt="Samsung manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Samsung</span></a><a href="/citizen" class="nav__item" style="--color: #0e0e0e;" data-v-c4377d1e=""><div class="smart-image nav__img" title="Citizen" data-v-c4377d1e="" data-v-1460e71d=""><picture data-v-1460e71d=""><source srcset="/thumbs/brands/s/246-citizen_logo.webp" type="image/webp" data-v-1460e71d=""><img src="/thumbs/brands/s/246-citizen_logo.jpg" width="100" height="100" alt="Citizen manuals" loading="lazy" data-v-1460e71d=""></picture></div><!----><!----><span data-v-c4377d1e="">Citizen</span></a><!--]--></nav>'''

soup = BeautifulSoup(html_content, 'html.parser')

# Extract all brand names within <span> tags in the navigation section
brand_names = [span.get_text() for span in soup.select('.nav__item span')]

# Create URLs with the extracted brand names
links = [f"https://www.manua.ls/{brand.lower()}" for brand in brand_names]

# Process each URL to replace spaces with hyphens
processed_links = [link.replace(" ", "-") for link in links]

# Display the processed links
print(processed_links)

from bs4 import BeautifulSoup
import requests
from tqdm import tqdm
import os
import json
from collections import OrderedDict
import math
import urllib.parse

# Set save directory and file paths
save_dir = "content/drive/My Drive/nvidia_competition/docextract"
if not os.path.exists(save_dir):
    os.makedirs(save_dir)

save_file = "links_2.json"
save_path = os.path.join(save_dir, save_file)

# Direct list of brand URLs
links = processed_links

# Function to retrieve models from each brand
def get_model_links(url):
    brand = url.split("/")[-1]
    model_links = []

    counter = 1
    max_count = 100
    while counter <= max_count:
        content = requests.get(url + "?p=" + str(counter))
        soup = BeautifulSoup(content.text, 'html.parser')

        # Check for pagination count on first page load
        if counter == 1:
            pagination = soup.find("div", class_="pagination pull-right")
            if pagination:
                text_ = pagination.find("span").text.strip()
                try:
                    per_page_count = int(text_.split(" ")[-3])
                    total_items = int(text_.split(" ")[-1])
                    max_count = math.ceil(total_items / per_page_count)
                except Exception as e:
                    print(f"Error parsing pagination on {url}: {e}")
                    break

        # Extract model links
        model_divs = soup.find_all("a", class_="d-flex w-100 text-dark text-decoration-none")
        for model in model_divs:
            model_href = model['href']
            model_name = model.find("h5", class_="h6").text
            model_url = urllib.parse.urljoin("https://www.manua.ls", model_href)
            model_links.append({"model_name": model_name, "model_url": model_url})

        counter += 1

    return brand, model_links

# Create dictionary to hold brand and model data
all_manuals = OrderedDict()
all_manuals['All_Manuals'] = []

# Iterate over each brand link and extract model links
for brand_url in tqdm(links):
    brand, model_links = get_model_links(brand_url)
    if model_links:
        all_manuals['All_Manuals'].append({
            "brand": brand,
            "models": model_links
        })

# Save data to JSON file
with open(save_path, "w") as f:
    json.dump(all_manuals, f, indent=2)

print("Brand and model links saved to:", save_path)

import json

# Save 'all_manuals' as a JSON file in the runtime
file_path = '/content/all_manuals.json'

from google.colab import files

# Save all_manuals to a JSON file locally within the Colab environment
file_path = '/content/all_manuals.json'
with open(file_path, 'w') as f:
    json.dump(all_manuals, f, indent=2)

# Trigger the file download to your local device
files.download(file_path)

with open(file_path, 'w') as f:
    json.dump(all_manuals, f, indent=2)

print(f"File saved as {file_path}")

from google.colab import drive
import json

# Mount Google Drive
drive.mount('/content/drive')

# Define the path to your JSON file
json_file_path = '/content/drive/My Drive/Colab Notebooks/nvidia_competition/docextract/all_manuals_links.json'

# Load the JSON data
with open(json_file_path, 'r') as f:
    all_manuals = json.load(f)

# Initialize an empty list to store Bosch URLs
bosch_urls = []

# Iterate through the data to retrieve Bosch model URLs
for entry in all_manuals['All_Manuals']:
    if entry['brand'].lower() == 'bosch':  # Check if the brand is Bosch
        for model in entry['models']:
            bosch_urls.append(model['model_url'])  # Append model URL to the list

# Print the list of Bosch URLs
print("Bosch URLs:", bosch_urls)

import requests
from bs4 import BeautifulSoup
import time
import json
from google.colab import files

# Function to extract the total number of pages
def extract_total_pages(url):
    try:
        response = requests.get(url)
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'html.parser')
            page_info = soup.find('button', class_='btn')
            if page_info:
                page_text = page_info.get_text(strip=True).replace(' ', '')
                if '/' in page_text:
                    total_pages = page_text.split('/')[1]
                    print(f"Extracted total pages: {total_pages}")
                    return int(total_pages)  # Convert to integer for iteration
                else:
                    print(f"Page format incorrect: '{page_text}'")
                    return None
            else:
                print("No page information found.")
                return None
        else:
            print(f"Error: Page at {url} does not exist (Status Code: {response.status_code}).")
            return None
    except Exception as e:
        print(f"Error scraping {url}: {str(e)}")
        return None

# Function to scrape the content from a single page
def scrape_page(url):
    try:
        response = requests.get(url)
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'html.parser')
            content = soup.find_all('div', class_='t')  # Adjust this selector based on actual content
            if content:
                page_content = [item.get_text(strip=True) for item in content]
                return page_content
            else:
                print(f"No content found on {url}. Assuming it's the last page.")
                return None
        else:
            print(f"Error: Page at {url} does not exist (Status Code: {response.status_code}).")
            return None
    except Exception as e:
        print(f"Error scraping {url}: {str(e)}")
        return None

# Function to scrape all pages for a given product URL
def scrape_all_pages(model_url):
    # First, get the total number of pages
    total_pages = extract_total_pages(model_url)
    if total_pages is None:
        print("Error: Could not extract total pages.")
        return []

    all_page_content = []  # List to store all scraped content

    # Iterate through all the pages
    for page_number in range(1, total_pages + 1):
        current_url = f"{model_url}?p={page_number}"
        print(f"Scraping page {page_number}/{total_pages}: {current_url}...")

        # Scrape the page content
        page_content = scrape_page(current_url)
        if not page_content:
            break  # Stop if no content is found on the page

        # Add the page content to the list along with the page number, product, and brand
        all_page_content.append({
            "page_number": page_number,
            "content": page_content,
            "product": "Bosch Serie 4 WAN282E",  # Replace with actual product name if available
            "brand": "Bosch"  # Replace with actual brand if available
        })

        # Optional: Delay between requests to avoid overloading the server
        time.sleep(1)

    return all_page_content

# Example model URL for Bosch (replace with the actual model URL)
model_url = "https://www.manua.ls/bosch/serie-4-wan282euro/manual"  # Replace this with the actual model URL

# Scrape all pages for the Bosch model
scraped_data = scrape_all_pages(model_url)

# Define the path to save the file in the Colab environment
save_file = "/content/scraped_data.json"

# Save the scraped data as a JSON file in the Colab environment
with open(save_file, "w") as f:
    json.dump(scraped_data, f, indent=2)

# Download the file to your local device
files.download(save_file)

import requests
from bs4 import BeautifulSoup
import time
import json
from google.colab import files

# Function to extract the total number of pages
def extract_total_pages(url):
    try:
        response = requests.get(url)
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'html.parser')
            page_info = soup.find('button', class_='btn')
            if page_info:
                page_text = page_info.get_text(strip=True).replace(' ', '')
                if '/' in page_text:
                    total_pages = page_text.split('/')[1]
                    print(f"Extracted total pages: {total_pages}")
                    return int(total_pages)  # Convert to integer for iteration
                else:
                    print(f"Page format incorrect: '{page_text}'")
                    return None
            else:
                print("No page information found.")
                return None
        else:
            print(f"Error: Page at {url} does not exist (Status Code: {response.status_code}).")
            return None
    except Exception as e:
        print(f"Error scraping {url}: {str(e)}")
        return None

# Function to scrape the content from a single page
def scrape_page(url):
    try:
        response = requests.get(url)
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'html.parser')
            content = soup.find_all('div', class_='t')  # Adjust this selector based on actual content
            if content:
                page_content = [item.get_text(strip=True) for item in content]
                return page_content
            else:
                print(f"No content found on {url}. Assuming it's the last page.")
                return None
        else:
            print(f"Error: Page at {url} does not exist (Status Code: {response.status_code}).")
            return None
    except Exception as e:
        print(f"Error scraping {url}: {str(e)}")
        return None

# Function to scrape all pages for a given product URL
def scrape_all_pages(model_url, brand_name, product_name):
    # First, get the total number of pages
    total_pages = extract_total_pages(model_url)
    if total_pages is None:
        print(f"Error: Could not extract total pages for {brand_name}.")
        return []

    all_page_content = []  # List to store all scraped content

    # Iterate through all the pages
    for page_number in range(1, total_pages + 1):
        current_url = f"{model_url}?p={page_number}"
        print(f"Scraping page {page_number}/{total_pages}: {current_url}...")

        # Scrape the page content
        page_content = scrape_page(current_url)
        if not page_content:
            break  # Stop if no content is found on the page

        # Add the page content to the list along with the page number, product, and brand
        all_page_content.append({
            "page_number": page_number,
            "content": page_content,
            "product": product_name,  # Use the actual product name
            "brand": brand_name  # Use the actual brand name
        })

        # Optional: Delay between requests to avoid overloading the server
        time.sleep(1)

    return all_page_content

# Read the JSON file with all the manual links
with open('/content/drive/My Drive/Colab Notebooks/nvidia_competition/docextract/all_manuals_links.json') as f:
    all_manuals = json.load(f)

# Iterate through the data to retrieve model URLs and scrape content
for entry in all_manuals['All_Manuals']:
    brand_name = entry['brand']  # Access the 'brand' directly
    for model in entry['models']:
        product_name = model['model_name']  # Model name should be extracted from 'model_name'
        model_url = model['model_url']

        # Scrape all pages for the current model
        print(f"Scraping model URL: {model_url} for brand: {brand_name}")
        scraped_data = scrape_all_pages(model_url, brand_name, product_name)

        # Save the scraped data as a JSON file for each brand
        save_file = f"/content/{brand_name}_manuals.json"
        with open(save_file, "w") as f:
            json.dump(scraped_data, f, indent=2)

        # Print the status
        print(f"Saved data for {brand_name} - {product_name} to {save_file}")

        # Download the file to your local device
        files.download(save_file)

        # Optional: Delay between downloads to avoid overload
        time.sleep(2)